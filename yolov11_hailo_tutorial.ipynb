{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Train Yolov11n using Ultralytics\n",
        "First, use the pretrained model yolov11n to train the coco8 dataset."
      ],
      "metadata": {
        "id": "-elDybW4o5pV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZmqC-n7NwcVC"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install onnx\n",
        "!pip install onnxruntime-gpu\n",
        "!pip install onnxslim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolo11n.pt\")"
      ],
      "metadata": {
        "id": "e5JBOfyTxcqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sSTwDcPNyb4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(\"https://ultralytics.com/images/bus.jpg\")"
      ],
      "metadata": {
        "id": "7_TUGvDN0zib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Export to ONNX format\n",
        "After the training finish, convert the model to ONNX format. The yolov11n in the ONNX model will be use to convert to hailo format."
      ],
      "metadata": {
        "id": "iF4nQXN_pn3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(\n",
        "    format=\"onnx\",\n",
        "    imgsz=640,\n",
        "    device=0,\n",
        "    opset=11\n",
        ")"
      ],
      "metadata": {
        "id": "0JefsCZO3DKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YOLO(\"/content/runs/detect/train/weights/best.onnx\").predict(\"bus.jpg\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "akuYDjIp5W-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Setup the Hailo's Dataflow Compiler\n",
        "This tool is to convert the ONNX model into the HEF format to be used on the Hailo8."
      ],
      "metadata": {
        "id": "g4t5VXv0rRjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt install python3-pip\n",
        "!sudo apt install python3.10-venv\n",
        "!sudo apt-get install python3.10-dev python3.10-distutils python3-tk libfuse2 graphviz libgraphviz-dev\n",
        "!sudo pip install pygraphviz\n",
        "!sudo apt install wslu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gOAHyrd82Oe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 -m venv hdfc"
      ],
      "metadata": {
        "id": "PandWpKO7iVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important!\n",
        "\n",
        "1. Download the .whl file from https://hailo.ai/developer-zone/software-downloads/\n",
        "2. Choose Software Package: AI Software Suite -> Dataflow Compiler -> x86 -> Linux -> Python 3.10\n",
        "3. Download the package the local and upload into this session runtime\n",
        "4. Make sure the uploading is complete first before installing it\n",
        "\n"
      ],
      "metadata": {
        "id": "wpoU9dYhsTU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfc/bin/pip install /content/hailo_dataflow_compiler-3.31.0-py3-none-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "wnYSmScw7qPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfc/bin/hailo --version"
      ],
      "metadata": {
        "id": "6D4Fb8NF_PdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Convert to Hailo format"
      ],
      "metadata": {
        "id": "PrXupuD0uSTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Parse the ONNX to HAR"
      ],
      "metadata": {
        "id": "XNmcvAjmuwyC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1XBtu3iRFzu"
      },
      "outputs": [],
      "source": [
        "with open(\"translate_model.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Define the ONNX model path and configuration\n",
        "onnx_path = \"/content/runs/detect/train/weights/best.onnx\"\n",
        "onnx_model_name = \"yolov11n\"\n",
        "chosen_hw_arch = \"hailo8\"  # Specify the target hardware architecture\n",
        "\n",
        "# Initialize the ClientRunner\n",
        "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
        "\n",
        "# Use the recommended end node names for translation for yolo\n",
        "end_node_names = [\n",
        "    \"/model.23/cv2.0/cv2.0.2/Conv\",\n",
        "    \"/model.23/cv3.0/cv3.0.2/Conv\",\n",
        "    \"/model.23/cv2.1/cv2.1.2/Conv\",\n",
        "    \"/model.23/cv3.1/cv3.1.2/Conv\",\n",
        "    \"/model.23/cv2.2/cv2.2.2/Conv\",\n",
        "    \"/model.23/cv3.2/cv3.2.2/Conv\"\n",
        "]\n",
        "net_input_shapes={\"input\": [1, 3, 640, 640]},  # Adjust input shapes if needed\n",
        "\n",
        "try:\n",
        "    # Translate the ONNX model to Hailo's format\n",
        "    hn, npz = runner.translate_onnx_model(\n",
        "        onnx_path,\n",
        "        onnx_model_name,\n",
        "        end_node_names=end_node_names,\n",
        "        # net_input_shapes=net_input_shapes,  # Adjust input shapes if needed\n",
        "    )\n",
        "    print(\"Model translation successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during model translation: {e}\")\n",
        "    raise\n",
        "\n",
        "# Save the Hailo model HAR file\n",
        "hailo_model_har_name = f\"{onnx_model_name}.har\"\n",
        "try:\n",
        "    runner.save_har(hailo_model_har_name)\n",
        "    print(f\"HAR file saved as: {hailo_model_har_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving HAR file: {e}\")\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfc/bin/python translate_model.py"
      ],
      "metadata": {
        "id": "qEwzcdL73_rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2.  Inspect the HAR"
      ],
      "metadata": {
        "id": "I9MilOrkvTwz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukdCnqNhoGmf"
      },
      "outputs": [],
      "source": [
        "with open(\"inspect_dict.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Load the HAR file\n",
        "har_path = \"yolov11n.har\"\n",
        "\n",
        "runner = ClientRunner(har=har_path)\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "try:\n",
        "    # Access the HailoNet as an OrderedDict\n",
        "    hn_dict = runner.get_hn()  # Or use runner._hn if get_hn() is unavailable\n",
        "    print(\"Inspecting layers from HailoNet (OrderedDict):\")\n",
        "\n",
        "    # Pretty-print each layer\n",
        "    for key, value in hn_dict.items():\n",
        "        print(f\"Key: {key}\")\n",
        "        pprint(value)\n",
        "        print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")  # Add a separator between layers for clarity\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error while inspecting hn_dict: {e}\")\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfc/bin/python inspect_dict.py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mB2q3ken5NDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Prepare the calibration data"
      ],
      "metadata": {
        "id": "Ib9TEGJMvknp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "# from google.colab import drive\n",
        "\n",
        "# Mounting Google Drive\n",
        "# drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Paths to directories and files\n",
        "image_dir = '/content/datasets/coco8/images/val'\n",
        "output_dir = '/content/'\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# File paths for saving calibration data\n",
        "calibration_data_path = os.path.join(output_dir, \"calibration_data.npy\")\n",
        "processed_data_path = os.path.join(output_dir, \"processed_calibration_data.npy\")\n",
        "\n",
        "# Initialize an empty list for calibration data\n",
        "calib_data = []\n",
        "\n",
        "# Process all image files in the directory\n",
        "for img_name in os.listdir(image_dir):\n",
        "    img_path = os.path.join(image_dir, img_name)\n",
        "    if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img = Image.open(img_path).resize((640, 640))  # Resize to desired dimensions\n",
        "        img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
        "        calib_data.append(img_array)\n",
        "\n",
        "# Convert the calibration data to a NumPy array\n",
        "calib_data = np.array(calib_data)\n",
        "\n",
        "# Save the normalized calibration data\n",
        "np.save(calibration_data_path, calib_data)\n",
        "print(f\"Normalized calibration dataset saved with shape: {calib_data.shape} to {calibration_data_path}\")\n",
        "\n",
        "# Scale the normalized data back to [0, 255]\n",
        "processed_calibration_data = calib_data * 255.0\n",
        "\n",
        "# Save the processed calibration data\n",
        "np.save(processed_data_path, processed_calibration_data)\n",
        "print(f\"Processed calibration dataset saved with shape: {processed_calibration_data.shape} to {processed_data_path}\")"
      ],
      "metadata": {
        "id": "DtNltSVi5e-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. Create the NMS config in json"
      ],
      "metadata": {
        "id": "ClNcHN8OwZq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Updated NMS layer configuration dictionary\n",
        "nms_layer_config = {\n",
        "    \"nms_scores_th\": 0.2,\n",
        "    \"nms_iou_th\": 0.7,\n",
        "    \"image_dims\": [\n",
        "        640,\n",
        "        640\n",
        "    ],\n",
        "    \"max_proposals_per_class\": 100,\n",
        "    \"classes\": 80,\n",
        "    \"regression_length\": 16,\n",
        "    \"background_removal\": False,\n",
        "    \"background_removal_index\": 0,\n",
        "    \"bbox_decoders\": [\n",
        "        {\n",
        "            \"name\": \"bbox_decoder51\",\n",
        "            \"stride\": 8,\n",
        "            \"reg_layer\": \"conv51\",\n",
        "            \"cls_layer\": \"conv54\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"bbox_decoder62\",\n",
        "            \"stride\": 16,\n",
        "            \"reg_layer\": \"conv62\",\n",
        "            \"cls_layer\": \"conv65\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"bbox_decoder77\",\n",
        "            \"stride\": 32,\n",
        "            \"reg_layer\": \"conv77\",\n",
        "            \"cls_layer\": \"conv80\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Path to save the updated JSON configuration\n",
        "output_dir = \"/content/\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "output_path = os.path.join(output_dir, \"yolov11n_nms_config.json\")\n",
        "\n",
        "# Save the updated configuration as a JSON file\n",
        "with open(output_path, \"w\") as json_file:\n",
        "    json.dump(nms_layer_config, json_file, indent=4)\n",
        "\n",
        "print(f\"NMS layer configuration saved to {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pvdiYMnC6JNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5. Optimize to HAR quantize"
      ],
      "metadata": {
        "id": "PPv3g47UwpAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz0_9dM5S97P"
      },
      "outputs": [],
      "source": [
        "with open(\"optimize_model.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import os\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Define your model's HAR file name\n",
        "model_name = \"yolov11n\"\n",
        "hailo_model_har_name = f\"{model_name}.har\"\n",
        "\n",
        "# Ensure the HAR file exists\n",
        "assert os.path.isfile(hailo_model_har_name), \"Please provide a valid path for the HAR file\"\n",
        "\n",
        "# Initialize the ClientRunner with the HAR file\n",
        "runner = ClientRunner(har=hailo_model_har_name)\n",
        "\n",
        "# Define the model script to add a normalization layer\n",
        "# Normalization for [0, 1] range\n",
        "alls = \\\"\\\"\\\"\n",
        "normalization1 = normalization([0.0, 0.0, 0.0], [255.0, 255.0, 255.0])\n",
        "change_output_activation(conv54, sigmoid)\n",
        "change_output_activation(conv65, sigmoid)\n",
        "change_output_activation(conv80, sigmoid)\n",
        "nms_postprocess(\"/content/yolov11n_nms_config.json\", meta_arch=yolov8, engine=cpu)\n",
        "\n",
        "allocator_param(width_splitter_defuse=disabled)\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "# Load the model script into the ClientRunner\n",
        "runner.load_model_script(alls)\n",
        "\n",
        "# Define a calibration dataset\n",
        "# Replace 'calib_dataset' with the actual dataset you're using for calibration\n",
        "# For example, if it's a directory of images, prepare the dataset accordingly\n",
        "calib_dataset = \"/content/processed_calibration_data.npy\"\n",
        "\n",
        "# Perform optimization with the calibration dataset\n",
        "runner.optimize(calib_dataset)\n",
        "\n",
        "# Save the optimized model to a new Quantized HAR file\n",
        "quantized_model_har_path = f\"{model_name}_quantized_model.har\"\n",
        "runner.save_har(quantized_model_har_path)\n",
        "\n",
        "print(f\"Quantized HAR file saved to: {quantized_model_har_path}\")\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfc/bin/python optimize_model.py"
      ],
      "metadata": {
        "id": "R5jPwYU78Ipv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6. Compile the HAR quantize to HEF"
      ],
      "metadata": {
        "id": "6Jtf8Elyw0oY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-YusemkPaUp"
      },
      "outputs": [],
      "source": [
        "with open(\"compile_model.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Define the quantized model HAR file\n",
        "model_name = \"yolov11n\"\n",
        "quantized_model_har_path = f\"{model_name}_quantized_model.har\"\n",
        "\n",
        "# Initialize the ClientRunner with the HAR file\n",
        "runner = ClientRunner(har=quantized_model_har_path)\n",
        "print(\"[info] ClientRunner initialized successfully.\")\n",
        "\n",
        "# Compile the model\n",
        "try:\n",
        "    hef = runner.compile()\n",
        "    print(\"[info] Compilation completed successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"[error] Failed to compile the model: {e}\")\n",
        "    raise\n",
        "file_name = f\"{model_name}.hef\"\n",
        "with open(file_name, \"wb\") as f:\n",
        "    f.write(hef)\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfc/bin/python compile_model.py"
      ],
      "metadata": {
        "id": "pbuoh8k28ZtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfc/bin/hailo profiler yolov11n_quantized_model.har"
      ],
      "metadata": {
        "id": "NU-khGIeVd1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}